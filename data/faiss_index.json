{
  "documents": [
    {
      "id": "9d57ba83-f481-4da1-b910-122d8684ae6c",
      "filename": "cs21b2021_final_report.pdf",
      "file_type": "application/pdf",
      "processed_at": "2025-07-18T16:20:48.034582",
      "text_length": 51901
    },
    {
      "id": "3334178a-198f-4ff3-bb11-795ab7bae0c5",
      "filename": "Bharath_resume.pdf",
      "file_type": "application/pdf",
      "processed_at": "2025-07-18T16:22:44.455662",
      "text_length": 3384
    }
  ],
  "chunks": [
    {
      "doc_id": "9d57ba83-f481-4da1-b910-122d8684ae6c",
      "chunk_idx": 0,
      "text": "AI-Powered Cattle Recognition and Assistance A Final Project End Semester Report submitted by KONETI SAI DHEERAJ (CS21B2021) in partial fulfilment of requirements for the award of the degree of BACHELOR OF TECHNOLOGY Department of Computer Science and Engineering INDIAN INSTITUTE OF INFORMATION TECHNOLOGY, DESIGN AND MANUFACTURING, KANCHEEPURAM May 2025 DECLARATION OF ORIGINALITY I,Koneti Sai Dheeraj , with Roll No: CS21B2021 hereby declare that the material presented in the Project Report titled AI-Powered Cattle Recognition and Assistance represents original work carried out by me in the Department of Computer Science and Engineering at the Indian Institute of Information Technology, Design and Manu- facturing, Kancheepuram. With my signature, I certify that: \u2022 I have not manipulated any of the data or results. \u2022 I have not committed any plagiarism of intellectual property. I have clearly indi- cated and referenced the contributions of others. \u2022 I have explicitly acknowledged all collaborative research and discussions. \u2022 I have understood that any false claim will result in severe disciplinary action. \u2022 I have understood that the work may be screened for any form of academic mis- conduct. Koneti Sai Dheeraj Place: Chennai Date: 05.05.2025 CERTIFICATE This is to certify that the report titled AI-Powered Cattle Recognition and Assis- tance , submitted by Koneti Sai Dheeraj (CS21B2021) , to the Indian Institute of Infor- mation Technology, Design and Manufacturing Kancheepuram, in partial fulfilment of requirements for the award of the degree of BACHELOR OF TECHNOLOGY is a bonafide record of the work done by him/her under my supervision. The contents of this report, in full or in parts, have not been submitted to any other Institute or University for the award of any degree or diploma. Dr. RAHUL RAMAN Project Internal Guide Assistant Professor Department of Computer Science and Engineering IIITDM Kancheepuram, Chennai - 600 127 Place: Chennai Date: ACKNOWLEDGEMENTS I would like to express my deepest appreciation to my mentor, Dr.Rahul Raman,for his unwavering support and technical expertise. Furthermore, I extend my heartfelt thanks to the faculty at IIITDM Kancheepuram for their continued support throughout this endeavor.. i ABSTRACT The AI-Powered Cattle Recognition and Assistance system introduces an innovative solution for livestock management through state-of-the-art computer vision and ar- tificial intelligence . By leveraging intelligent algorithms to detect and analyze unique muzzle patterns\u2014akin to human fingerprints , the system provides a robust alterna- tive to conventional tagging methods, ensuring accurate and permanent identification of individual cattle. This biometric approach eliminates common issues like tag loss or damage, creat- ing secure digital identities for every animal in the herd. It ensures reliable traceability and record-keeping, critical for modern farming operations. Planned enhancements include machine learning-driven disease detection (iden- tifying early visual symptoms of common bovine illnesses), an AI-powered chatbot for instant veterinary guidance, and a comprehensive medical management system to track vaccinations, treatments, and health histories. These additions aim to enable proactive health monitoring and data-driven decision-making. By addressing identification errors, accelerating disease prevention, and streamlin- ing health management workflows, the system promises to improve herd health, boost productivity, and optimize resource utilization across farms of all scales. KEYWORDS : Computer Vision; Biometric Identification; Muzzle Pattern Recog- nition; Livestock Management; Animal Health Monitoring; Dis- ease Detection; Artificial Intelligence in Agriculture. ii TABLE OF CONTENTS ACKNOWLEDGEMENTS i ABSTRACT ii LIST OF TABLES vi LIST OF FIGURES vii ABBREVIATIONS viii 1 INTRODUCTION 1 1.1 Problem Definition . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.2 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 1.3 Problem Statement . . . . . . . . . . . . . . . . . . . . . . . . . . 2 1.4 Objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 1.4.1 Core Identification Pipeline . . . . . . . . . . . . . . . . . 5 1.4.2 Health Monitoring Extensions . . . . . . . . . . . . . . . . 5 1.4.3 Farm Management Tools . . . . . . . . . . . . . . . . . . . 5 2 LITERATURE SURVEY 7 3 WORK DONE 9 3.1 Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 3.2 Cattle Muzzle Detection using YOLOv7 . . . . . . . . . . . . . . . 9 3.2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . 9 3.2.2 Dataset for Muzzle Detection . . . . . . . . . . . . . . . . 10 3.2.3 Detection Framework: YOLOv7 Implementation . . . . . . 11 3.2.4 YOLOv7 Training Methodology . . . . . . . . . . . . . . . 12 3.3 Muzzle Recognition and Feature Extraction . . . . . . . . . . . . . 14 3.3.1 Preprocessing Techniques . . . . . . . . . . . . . . . . . . 14 iii 3.3.2 Feature Extraction Techniques For Muzzle recognition . . . 16 3.4 Recognition Framework Development . . . . . . . . . . . . . . . . 18 3.4.1 ResNet50 - Deep Residual Network with Skip Connections . 18 3.5 Feature Extraction and Database Integration . . . . . . . . . . . . .",
      "filename": "cs21b2021_final_report.pdf"
    },
    {
      "doc_id": "9d57ba83-f481-4da1-b910-122d8684ae6c",
      "chunk_idx": 1,
      "text": ". . . . . . . . . . . 9 3.2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . 9 3.2.2 Dataset for Muzzle Detection . . . . . . . . . . . . . . . . 10 3.2.3 Detection Framework: YOLOv7 Implementation . . . . . . 11 3.2.4 YOLOv7 Training Methodology . . . . . . . . . . . . . . . 12 3.3 Muzzle Recognition and Feature Extraction . . . . . . . . . . . . . 14 3.3.1 Preprocessing Techniques . . . . . . . . . . . . . . . . . . 14 iii 3.3.2 Feature Extraction Techniques For Muzzle recognition . . . 16 3.4 Recognition Framework Development . . . . . . . . . . . . . . . . 18 3.4.1 ResNet50 - Deep Residual Network with Skip Connections . 18 3.5 Feature Extraction and Database Integration . . . . . . . . . . . . . 19 3.5.1 ResNet50 Adaptation for Muzzle Recognition . . . . . . . . 19 3.5.2 FAISS Database Integration . . . . . . . . . . . . . . . . . 19 3.6 Cattle Enrollment System . . . . . . . . . . . . . . . . . . . . . . . 20 3.7 Chatbot Integration for Veterinary Support . . . . . . . . . . . . . . 21 3.7.1 Data Sources . . . . . . . . . . . . . . . . . . . . . . . . . 21 3.7.2 Implementation Details . . . . . . . . . . . . . . . . . . . . 21 3.7.3 Mobile Application Implementation . . . . . . . . . . . . . 24 3.8 Key Innovations . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 4 CURRENT RESULTS 26 4.1 YOLO Training Metrics . . . . . . . . . . . . . . . . . . . . . . . 26 4.1.1 Precision, Recall, and F1-Score . . . . . . . . . . . . . . . 26 4.1.2 Training Metrics Graphs . . . . . . . . . . . . . . . . . . . 27 4.2 ResNet50 Recognition Performance . . . . . . . . . . . . . . . . . 28 4.2.1 Feature Extraction and Database Integration . . . . . . . . . 28 4.3 Chatbot Integration and Mobile App Interface . . . . . . . . . . . . 29 4.3.1 LLM-Powered Veterinary Chatbot . . . . . . . . . . . . . . 29 4.3.2 Flutter-Based Mobile Application . . . . . . . . . . . . . . 29 4.4 Integrated System Development . . . . . . . . . . . . . . . . . . . 32 4.4.1 Two-Stage Pipeline Architecture . . . . . . . . . . . . . . . 32 4.4.2 Evaluation Metrics . . . . . . . . . . . . . . . . . . . . . . 32 4.5 Current Implementation Status . . . . . . . . . . . . . . . . . . . . 32 5 OUR COLLABORATIVE CONTRIBUTIONS 33 5.1 Initial Research and Planning . . . . . . . . . . . . . . . . . . . . . 33 5.2 Building the Detection System . . . . . . . . . . . . . . . . . . . . 33 5.3 Developing the Recognition Pipeline . . . . . . . . . . . . . . . . . 34 5.4 Integrating the Complete System . . . . . . . . . . . . . . . . . . . 34 iv 5.5 Documentation and Future Vision . . . . . . . . . . . . . . . . . . 35 6 FUTURE SCOPE 36 6.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 6.2 Lightweight Image Enhancement . . . . . . . . . . . . . . . . . . . 36 6.3 Edge-Optimized YOLOv7 Deployment . . . . . . . . . . . . . . . 37 6.4 Integrated Disease Detection . . . . . . . . . . . . . . . . . . . . . 37 6.5 Mobile Application Enhancements . . . . . . . . . . . . . . . . . . 37 6.6 AI Veterinary Assistant . . . . . . . . . . . . . . . . . . . . . . . . 38 6.7 Technical Refinements . . . . . . . . . . . . . . . . . . . . . . . . 38 REFERENCES 39 LIST OF TABLES 4.1 ResNet50 Performance Metrics . . . . . . . . . . . . . . .",
      "filename": "cs21b2021_final_report.pdf"
    },
    {
      "doc_id": "9d57ba83-f481-4da1-b910-122d8684ae6c",
      "chunk_idx": 2,
      "text": ". . . . . . . . . . . . . . . . . . . . . . . . . 36 6.2 Lightweight Image Enhancement . . . . . . . . . . . . . . . . . . . 36 6.3 Edge-Optimized YOLOv7 Deployment . . . . . . . . . . . . . . . 37 6.4 Integrated Disease Detection . . . . . . . . . . . . . . . . . . . . . 37 6.5 Mobile Application Enhancements . . . . . . . . . . . . . . . . . . 37 6.6 AI Veterinary Assistant . . . . . . . . . . . . . . . . . . . . . . . . 38 6.7 Technical Refinements . . . . . . . . . . . . . . . . . . . . . . . . 38 REFERENCES 39 LIST OF TABLES 4.1 ResNet50 Performance Metrics . . . . . . . . . . . . . . . . . . . . 29 vi LIST OF FIGURES 3.1 Close-up muzzle sample (Phase 1) . . . . . . . . . . . . . . . . . . 11 3.2 Close-up muzzle sample (Phase 1) . . . . . . . . . . . . . . . . . . 11 3.3 Color variation sample (Phase 2) . . . . . . . . . . . . . . . . . . . 11 3.4 Sample image from initial dataset . . . . . . . . . . . . . . . . . . 14 3.5 Close-up muzzle sample (Phase 1) . . . . . . . . . . . . . . . . . . 14 3.6 Color variation sample (Phase 2) . . . . . . . . . . . . . . . . . . . 14 3.7 Muzzle image of same Cattle . . . . . . . . . . . . . . . . . . . . . 17 3.8 Matches After applying SIFT . . . . . . . . . . . . . . . . . . . . . 17 3.9 ResNet50 Architecture with Residual Connections . . . . . . . . . 19 3.10 Cattle registration interface showing ID generation and image upload functionality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 3.11 Chatbot interface for veterinary advice in the mobile application . . 23 3.12 Mobile application interface showing the cattle identification feature 25 4.1 P-curve . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 4.2 R-curve . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 4.3 F1score-curve . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 4.4 Training Metrics Graphs . . . . . . . . . . . . . . . . . . . . . . . 28 4.5 Chatbot interface for veterinary advice in the mobile application . . 30 4.6 Mobile application interface showing the cattle identification feature 31 vii ABBREVIATIONS AI Artificial Intelligence RFID Radio Frequency Identification YOLO You Only Look Once SRGAN Super-Resolution Generative Adversarial Network ESRGAN Enhanced Super-Resolution Generative Adversarial Network VGG Visual Geometry Group LLM Large Language Model RAG Retrieval Augmented Generation viii CHAPTER 1 INTRODUCTION 1.1 Problem Definition Traditional identification technologies such as ear tags, hot and cold branding, and RFID chips are plagued with inherent weaknesses. Tags drop off, implants fail, and paper record-keeping allows for mistakes, with error rate up to 10-15% in big herds[1]. Even newer systems have their challenges: RFID readers are hindered by interference, and expense is still too high for small-scale farmers. These loopholes provide inconsis- tent trails of data, making disease surveillance, breeding programs, and market trace- ability problematic. Nature provides a superior solution. Cattle have distinctive muzzle patterns\u2014intricate patterns of ridges, creases, and pigmentation\u2014that are permanent from birth to maturity[2][3]. In contrast to plastic tags or electronic implants, these biological \"fingerprints\" cannot be lost, stolen, or tampered with. However, until recently, it took a time-consuming, subjective process to use this trait\u2014the human eye had to manually compare the muz- zle patterns. Health management also encounters the same bottlenecks. Foot-and-mouth or mas- titis diseases spread quickly in densely populated barns, but early signs are not always apparent until swelling or behavioral changes are visible. Physical examination by vet- erinarians is still the gold standard, but delayed diagnosis due to lack of staff or budget constraints permits outbreaks to grow out of control[4]. Farmers have no tools for proactive monitoring, and herds remain susceptible to avoidable losses. The AI-Powered Cattle Identification System fills these gaps. By streamlining muzzle pattern analysis with computer vision and integrating predictive health un- derstanding through machine learning, it turns identification into a worry-free, error- impenetrable process. This is more than an improvement on tagging it is an evolution toward data driven livestock management. CHAPTER 1. INTRODUCTION CS21B2021 1.2 Motivation Today\u2019s farms require smarter technology to take good care of animals. Manual meth- ods such as pen-and-paper tagging or in-person checks are not able to keep up with the needs of intensive agriculture.",
      "filename": "cs21b2021_final_report.pdf"
    },
    {
      "doc_id": "9d57ba83-f481-4da1-b910-122d8684ae6c",
      "chunk_idx": 3,
      "text": "or electronic implants, these biological \"fingerprints\" cannot be lost, stolen, or tampered with. However, until recently, it took a time-consuming, subjective process to use this trait\u2014the human eye had to manually compare the muz- zle patterns. Health management also encounters the same bottlenecks. Foot-and-mouth or mas- titis diseases spread quickly in densely populated barns, but early signs are not always apparent until swelling or behavioral changes are visible. Physical examination by vet- erinarians is still the gold standard, but delayed diagnosis due to lack of staff or budget constraints permits outbreaks to grow out of control[4]. Farmers have no tools for proactive monitoring, and herds remain susceptible to avoidable losses. The AI-Powered Cattle Identification System fills these gaps. By streamlining muzzle pattern analysis with computer vision and integrating predictive health un- derstanding through machine learning, it turns identification into a worry-free, error- impenetrable process. This is more than an improvement on tagging it is an evolution toward data driven livestock management. CHAPTER 1. INTRODUCTION CS21B2021 1.2 Motivation Today\u2019s farms require smarter technology to take good care of animals. Manual meth- ods such as pen-and-paper tagging or in-person checks are not able to keep up with the needs of intensive agriculture. Tags get lost, implants reject, and handwritten paper creates bottlenecks\u2014losing time, costing more money, and causing holes in valuable data. Farmers require solutions that integrate flawlessly with real-world realities, from mucky barnyards to out-of-the-way pastures. Key points for Innovation: \u2022Growing Regulatory Needs: Traceability regulations demand increasingly de- tailed, tamper-resistant histories of animal movement and health. Older systems can\u2019t be agile enough to cope with strict requirements, threatening fines for non- compliance. \u2022The Cost of Dated ID Solutions: Ear tags snap off, RFID chips deteriorate, and manual scans take hours away from other work. In big herds, replacing broken identifiers is an ongoing expense\u2014time- and labor-intensive. \u2022Precision on the Line: Mistaken identities result in defective vaccination records, false breeding documents, and disease outbreaks gone unchecked. Existing prac- tices simply aren\u2019t able to provide the level of precision modern agriculture de- mands. \u2022One-Size-Fits-All Won\u2019t Cut It: An industrial dairy system may be too much for a smallholder, but reducing sophisticated tech often eliminates its utility. So- lutions have to walk a line between robustness and ease of use for farm size. \u2022Closing the Vision-Reality Gap: As computer vision revolutionizes retail and manufacturing industries [5], its application in livestock care is limited. An affordable camera-based identification system might enable farmers to monitor health trends, identify sick animals early, and minimize dependence on error- ridden manual procedures\u2014even in limited-resource environments. 1.3 Problem Statement This project seeks to develop an AI-powered cattle recognition system that uses muzzle patterns as biometric markers, similar to fingerprints. In contrast to conventional tag- ging systems with a high risk of loss or damage, our system is based on non-invasive camera recognition and includes software for health tracking and veterinary advice. Department of CSE, IIITDM Kancheepuram, May 2025 2 CHAPTER 1. INTRODUCTION CS21B2021 Core System Elements \u2022YOLOv7 Muzzle Detection: \u2013A YOLOv7 model ([6]) identifies muzzle areas within uploaded images \u2013The model was trained on a custom dataset with personally annotated muz- zle patterns \u2022ResNet50-Based Feature Extraction: \u2013A ResNet50 backbone with modifications (loaded from FEAT_WEIGHTS ) extracts normalized 2048D embeddings from muzzle images after cropping \u2013These embeddings are matched against a FAISS vector database of pre- stored cattle identities ( cattle_embs.pkl ) via cosine similarity-based identification \u2022Health Monitoring & Chatbot Integration: \u2013The system facilitates future extensions such as disease diagnosis by tap- ping into metadata from PDFs/JSONs processed through pdfplumber andLangChain \u2013A Groq-driven LLM chatbot delivers real-time veterinary consultations by searching a FAISS index of cattle disease literature Technical Scope \u2022Robustness: The pipeline handles varying lighting and low-resolution inputs via YOLOv7\u2019s detection logic (padding correction in crop_first_muzzle ) and normalized feature comparisons \u2022Scalability: New cattle are inserted through the /add endpoint, updating the FAISS database with embeddings and metadata \u2022Future-Proof Design: Identification logic ( identify_cattle ) is separated from chatbot functionality ( /chat ), enabling independent upgrades to disease detection modules without affecting core operations Through the integration of computer vision (YOLOv7), vector similarity search, and LLM-driven Q&A, this system addresses shortcomings in conventional livestock management and supports data-driven health interventions. Constraints and Challenges Throughout the creation of our cattle muzzle identification system, we faced practical challenges that required continuous improvement to meet robust performance criteria in real-world farm scenarios. Department of CSE, IIITDM Kancheepuram, May 2025 3 CHAPTER 1. INTRODUCTION CS21B2021 Detection Challenges \u2022Proximity Detection Limitations: \u2013Initial versions of our YOLOv7 model (trained on 842 manually labeled muzzle samples, with 540 for training) struggled with muzzle detection when cattle were too close to the camera \u2013This limitation reduced usability in scenarios requiring fast close-range iden- tification \u2022Color Bias in Detection: \u2013After addressing proximity issues, we observed weak performance on lighter- colored muzzles (pink or creamy shades) \u2013The original dataset\u2019s bias toward darker muzzle colors resulted in detection performance disparities Dataset Enhancement Strategy To mitigate these problems, we implemented the following improvements: \u2022 Augmented our dataset with hand-annotated close-up muzzle images under vari- ous lighting conditions \u2022 Collected and labeled a secondary dataset featuring muzzles with diverse pig- mentation (e.g., pink, spotted patterns) \u2022 Combined these datasets and retrained the YOLOv7 model to enhance general- ization across distances and color profiles \u2022 Achieved a detection model capable of reliably bounding cattle muzzles in diverse conditions Identification Challenges \u2022Low-Quality Cropped Muzzle Images: \u2013Muzzle crops from YOLOv7 detection often appeared blurry or had uneven illumination \u2013This affected the reliability of feature extraction \u2022Model-Specific Feature Extraction: \u2013Our ResNet50-based feature extractor (loaded from FEAT_WEIGHTS ) pro- duces normalized 2048D embeddings \u2013Suboptimal image quality still impacted cosine similarity comparisons in the FAISS database ( cattle_embs.pkl ) Department of CSE, IIITDM Kancheepuram, May 2025 4 CHAPTER 1. INTRODUCTION CS21B2021 Future Improvements While SRGAN-based enhancement introduced synthetic artifacts that compromised ac- curacy, we plan to: \u2022 Fine-tune lightweight image restoration algorithms (e.g., histogram equalization or adaptive contrast enhancement) to improve crop quality without distorting bio- metric patterns \u2022",
      "filename": "cs21b2021_final_report.pdf"
    },
    {
      "doc_id": "9d57ba83-f481-4da1-b910-122d8684ae6c",
      "chunk_idx": 4,
      "text": "colored muzzles (pink or creamy shades) \u2013The original dataset\u2019s bias toward darker muzzle colors resulted in detection performance disparities Dataset Enhancement Strategy To mitigate these problems, we implemented the following improvements: \u2022 Augmented our dataset with hand-annotated close-up muzzle images under vari- ous lighting conditions \u2022 Collected and labeled a secondary dataset featuring muzzles with diverse pig- mentation (e.g., pink, spotted patterns) \u2022 Combined these datasets and retrained the YOLOv7 model to enhance general- ization across distances and color profiles \u2022 Achieved a detection model capable of reliably bounding cattle muzzles in diverse conditions Identification Challenges \u2022Low-Quality Cropped Muzzle Images: \u2013Muzzle crops from YOLOv7 detection often appeared blurry or had uneven illumination \u2013This affected the reliability of feature extraction \u2022Model-Specific Feature Extraction: \u2013Our ResNet50-based feature extractor (loaded from FEAT_WEIGHTS ) pro- duces normalized 2048D embeddings \u2013Suboptimal image quality still impacted cosine similarity comparisons in the FAISS database ( cattle_embs.pkl ) Department of CSE, IIITDM Kancheepuram, May 2025 4 CHAPTER 1. INTRODUCTION CS21B2021 Future Improvements While SRGAN-based enhancement introduced synthetic artifacts that compromised ac- curacy, we plan to: \u2022 Fine-tune lightweight image restoration algorithms (e.g., histogram equalization or adaptive contrast enhancement) to improve crop quality without distorting bio- metric patterns \u2022 Investigate domain-specific super-resolution models trained exclusively on muz- zle images to preserve critical texture details 1.4 Objectives 1.4.1 Core Identification Pipeline \u2022 Develop a YOLOv7-based detection system robust to varying distances, lighting conditions, and pigmentation \u2022 Achieve high recall and precision (target: mAP >95%) for reliable farm deploy- ment \u2022 Implement ResNet50 feature extraction for generating normalized muzzle em- beddings \u2022 Enable dynamic database updates via the /add endpoint for scalable herd man- agement 1.4.2 Health Monitoring Extensions \u2022 Deploy an LLM-RAG chatbot (using Groq\u2019s llama3-8b API) for real-time health consultations \u2022 Utilize FAISS-embedded disease literature ( cattle-diseases-farmers-guide.pdf , JSON data) \u2022 Future work: Implement early disease detection (e.g., coat changes, swelling) via transfer learning on labeled datasets 1.4.3 Farm Management Tools \u2022 Develop a digital health record system for tracking vaccinations, treatments, and medical history through /add Department of CSE, IIITDM Kancheepuram, May 2025 5 CHAPTER 1. INTRODUCTION CS21B2021 \u2022 Create automated reminders for routine procedures (vaccinations, deworming) based on FAISS metadata \u2022 Design a farmer dashboard for visualizing herd health trends and identification logs Department of CSE, IIITDM Kancheepuram, May 2025 6 CHAPTER 2 LITERATURE SURVEY The establishment of AI-based cattle identification systems using muzzle patterns builds upon advancements in computer vision, biometric recognition, and AI-driven livestock management. Key research areas include object detection for muzzle localization, fea- ture extraction for biometric matching, and AI applications in veterinary diagnostics. This chapter reviews foundational work and positions our contribution within the field. Managing livestock efficiently is crucial for farmers, but traditional identification methods like ear tags can be problematic[1]. This project explores an AI-based solution using computer vision to recognize cattle through their unique muzzle patterns and provide health assistance. The system first detects cattle in images using YOLOv7, a powerful object detection model known for its speed and accuracy[6]. Once detected, it targets the muzzle region because research indicates that the nose pattern of each cow is unique, much like a human fingerprint[2]. But images from farms are challenging to work with due to insufficient lighting, low resolution, and unusual perspectives that render recognition challenging. Several methods for the muzzle recognition task were tested. First, FaceNet with triplet loss was tried but failed because there was not enough training data and it performed badly on low-quality images[7]. Second, the SIFT algo- rithm was attempted but failed since it needs good, high-resolution images to be able to recognize features well[8]. The best solution was a custom-trained ResNet50 model that utilized deep learning to be able to identify cattle from imperfect images reliably. This agrees with current literature indicating that deep learning performs better than conventional methods for animal classification. In addition to identification, the system also has an AI assistant that will assist farmers with cattle health inquiries. The chatbot employs Retrieval-Augmented Generation (RAG) technology, which blends a database of cattle illnesses with sophisticated language processing.We mainly use RAG[9] to cus- tomize the LLM, the LLM we use here is LLAMA 3B. As opposed to basic chatbots CHAPTER 2. LITERATURE SURVEY CS21B2021 with pre-programmed answers, this system can deliver current, detailed responses by scouring trusted resources. This is especially useful in rural settings where veterinary guidance may not be readily at hand. The whole system is delivered in an end-user- friendly mobile application developed with Flutter, and it can be accessed by farmers on both Android and iOS phones[10]. With precise cattle identification alongside real- time health data, the project provides an effective solution to contemporary livestock management issues. Department of CSE, IIITDM Kancheepuram, May 2025 8 CHAPTER 3 WORK DONE 3.1 Preliminaries Initial Exploration: Cattle Muzzle Detection and Recognition First in this project, we investigated several deep learning approaches to recognize cat- tle from muzzle patterns. Cattle muzzle patterns, just like fingerprints in humans, are individual identifiers that can be used to recognize animals. We wanted to develop a ro- bust system that can efficiently detect and recognize individual cattle based on muzzle patterns. 3.2 Cattle Muzzle Detection using YOLOv7 3.2.1 Introduction Cattle muzzle patterns serve as unique biometric identifiers, analogous to human finger- prints. Traditional manual identification methods are time-consuming and error-prone, especially for large herds. Deep learning algorithms like YOLO have emerged as pow- erful tools for automating muzzle detection, enabling real-time, non-invasive identifi- cation. We employed a customized YOLOv7 architecture [6], chosen for its optimal bal- ance between speed and detection accuracy. Compared to YOLOv8 (considered in pre- liminary studies), YOLOv7\u2019s dynamic labeling and model scaling capabilities proved more effective for detecting muzzles under variable farm conditions including uneven lighting, partial occlusion, and diverse muzzle coloration. CHAPTER 3. WORK DONE CS21B2021 3.2.2 Dataset for Muzzle Detection We developed and validated our detection pipeline using an incrementally annotated dataset: Initial Dataset \u2022Size: 842 manually labeled muzzle images (collected via smartphone cameras and farm surveillance) \u2022Splits: \u2013Training:",
      "filename": "cs21b2021_final_report.pdf"
    },
    {
      "doc_id": "9d57ba83-f481-4da1-b910-122d8684ae6c",
      "chunk_idx": 5,
      "text": "Recognition First in this project, we investigated several deep learning approaches to recognize cat- tle from muzzle patterns. Cattle muzzle patterns, just like fingerprints in humans, are individual identifiers that can be used to recognize animals. We wanted to develop a ro- bust system that can efficiently detect and recognize individual cattle based on muzzle patterns. 3.2 Cattle Muzzle Detection using YOLOv7 3.2.1 Introduction Cattle muzzle patterns serve as unique biometric identifiers, analogous to human finger- prints. Traditional manual identification methods are time-consuming and error-prone, especially for large herds. Deep learning algorithms like YOLO have emerged as pow- erful tools for automating muzzle detection, enabling real-time, non-invasive identifi- cation. We employed a customized YOLOv7 architecture [6], chosen for its optimal bal- ance between speed and detection accuracy. Compared to YOLOv8 (considered in pre- liminary studies), YOLOv7\u2019s dynamic labeling and model scaling capabilities proved more effective for detecting muzzles under variable farm conditions including uneven lighting, partial occlusion, and diverse muzzle coloration. CHAPTER 3. WORK DONE CS21B2021 3.2.2 Dataset for Muzzle Detection We developed and validated our detection pipeline using an incrementally annotated dataset: Initial Dataset \u2022Size: 842 manually labeled muzzle images (collected via smartphone cameras and farm surveillance) \u2022Splits: \u2013Training: 540 images (64%) \u2013Validation: 168 images (20%) \u2013Testing: 134 images (16%) \u2022Annotation: Bounding boxes in YOLO format, focusing on muzzle regions \u2022Initial Challenges: Early models struggled with close-range detection and lighter muzzle colors (e.g., pink/cream shades) Improved Dataset (Phase 1: Close-Range Fixes) To address close-range detection issues: \u2022New Samples: 458 close-up muzzle photos (15-50 cm range) \u2022Collection: Controlled farm environments with varied lighting \u2022Annotation: Precision labeling via LabelImg for accurate bounding boxes Enhanced Dataset (Phase 2: Color Diversity) To reduce color bias: \u2022Added Samples: 300 images featuring light-colored muzzles (pink/cream) \u2022Breeds Covered: Holstein, Jersey, Angus, and Hereford \u2022Variability: Multiple angles, lighting conditions, and backgrounds Department of CSE, IIITDM Kancheepuram, May 2025 10 CHAPTER 3. WORK DONE CS21B2021 Final Dataset \u2022Total Size: 1,600 annotated images \u2022Augmentation: Horizontal flips, \u00b115\u00b0 rotations, brightness/contrast adjustments \u2022Validation: 5-fold cross-validation ensured robustness across breeds, distances, and pigmentation Figure 3.1: Close-up muz- zle sample (Phase 1) Figure 3.2: Close-up muz- zle sample (Phase 1) Figure 3.3: Color variation sample (Phase 2) Dataset Collection and Preparation To build a comprehensive dataset, we manually collected and annotated muzzle images from cattle: \u2022 1,600 samples were collected from different cattle under varying conditions \u2022 Images included variation in lighting, angles, and distances \u2022 Diverse muzzle colors and patterns were incorporated (black, pink, and mixed coloration) \u2022 Special attention was given to challenging cases for recognition 3.2.3 Detection Framework: YOLOv7 Implementation For the muzzle detection component, we implemented YOLOv7, the state-of-the-art object detection framework, due to its: Department of CSE, IIITDM Kancheepuram, May 2025 11 CHAPTER 3. WORK DONE CS21B2021 \u2022 Superior speed-accuracy trade-off, making it suitable for real-time applications in farm settings \u2022 Advanced feature extraction capabilities with a CSP (Cross Stage Partial) back- bone \u2022 Enhanced performance for small object detection, crucial for detailed muzzle pat- tern capture \u2022 Compatibility with edge devices for potential on-farm deployment 3.2.4 YOLOv7 Training Methodology Our manually annotated dataset of 1,600 cattle muzzle images was split into training (75%), validation (15.6%), and test (9.4%) sets. Annotations were created in YOLO format with a single class (\"muzzle\").[6] We utilized YOLOv7m (medium) as our base model for training. The training pro- cess spanned 150 epochs and utilized transfer learning from pre-trained weights. Loss Function Components YOLOv7 utilizes a composite loss function consisting of three primary components: 1.Box Regression Loss ( Lbox): \u2022 Uses Complete IoU (CIoU) loss which accounts for: \u2013Intersection over Union \u2013Central point distance \u2013Aspect ratio consistency \u2022 Mathematical formulation: Lbox= 1\u2212IoU+\u03c12(b, bgt) c2+\u03b1v (3.1) where \u03c1is the Euclidean distance between box centers, cis the diagonal length of the smallest enclosing box, \u03b1is a positive trade-off parameter, and vmeasures aspect ratio consistency. 2.Classification Loss ( Lcls): \u2022 Binary Cross-Entropy (BCE) loss for class prediction \u2022 Applied only where objects are present Department of CSE, IIITDM Kancheepuram, May 2025 12 CHAPTER 3. WORK DONE CS21B2021 \u2022 Formulation: Lcls=\u2212X i\u2208\u2126obj[yilog(\u02c6yi) + (1 \u2212yi) log(1 \u2212\u02c6yi)] (3.2) where \u2126objrepresents grid cells containing objects. 3.Distribution Focal Loss ( LDFL): \u2022 Provides more precise bounding box regression \u2022 Models the distribution of box coordinates rather than point estimates \u2022 Formulation: LDFL=\u2212nX i=1CX j=1yijlog(pij) (3.3) where yijis the ground truth distribution and pijis the predicted distribution. The total loss is a weighted combination of these components: Ltotal=\u03bb1Lbox+\u03bb2Lcls+\u03bb3LDFL (3.4) Where in our configuration: \u2022\u03bb1= 7.5(box loss gain) \u2022\u03bb2= 0.5(classification loss gain) \u2022\u03bb3= 1.5(distribution focal loss gain) Training Process and Convergence The training process followed three phases: 1.Warm-up Phase (Epochs 1-3): \u2022 Gradually increased learning rate from 0.1\u00d7 to 1\u00d7 of base learning rate \u2022 Stabilized gradient flow and prevented divergence due to randomly initial- ized detection heads 2.Main Training Phase (Epochs 4-135): \u2022 Learning rate followed a cosine annealing schedule \u2022 Applied scheduled augmentations with varying intensity \u2022 Monitored validation metrics to track generalization 3.Convergence Phase (Epochs 35): \u2022 Model reached stable performance with minimal oscillation \u2022 Early stopping patience of 15 epochs ensured training terminated at optimal point Department of CSE, IIITDM Kancheepuram, May 2025 13 CHAPTER 3. WORK DONE CS21B2021 Figure 3.4: Sample image from initial dataset Figure 3.5: Close-up muz- zle sample (Phase 1) Figure 3.6: Color variation sample (Phase 2) 3.3 Muzzle Recognition and Feature Extraction 3.3.1 Preprocessing Techniques After getting the muzzle image from the cattle, we proceed to recognition , but before that we apply pre processing techinques to increase the productivity of the mdoel and reduce noise.[7] Sharpening Sharpening is a preprocessing technique used to enhance edges and fine details in an image by amplifying high-frequency components. The sharpening process can be math- ematically represented as: g(x, y) =f(x, y) +k\u00b7gmask(x, y) (3.5) where: \u2022f(x, y)is the original image . \u2022g(x, y)is the sharpened image . \u2022gmask(x, y)is the mask , obtained by subtracting a blurred version of the image from its original version. Department of CSE, IIITDM Kancheepuram, May 2025 14 CHAPTER",
      "filename": "cs21b2021_final_report.pdf"
    },
    {
      "doc_id": "9d57ba83-f481-4da1-b910-122d8684ae6c",
      "chunk_idx": 6,
      "text": "(Epochs 4-135): \u2022 Learning rate followed a cosine annealing schedule \u2022 Applied scheduled augmentations with varying intensity \u2022 Monitored validation metrics to track generalization 3.Convergence Phase (Epochs 35): \u2022 Model reached stable performance with minimal oscillation \u2022 Early stopping patience of 15 epochs ensured training terminated at optimal point Department of CSE, IIITDM Kancheepuram, May 2025 13 CHAPTER 3. WORK DONE CS21B2021 Figure 3.4: Sample image from initial dataset Figure 3.5: Close-up muz- zle sample (Phase 1) Figure 3.6: Color variation sample (Phase 2) 3.3 Muzzle Recognition and Feature Extraction 3.3.1 Preprocessing Techniques After getting the muzzle image from the cattle, we proceed to recognition , but before that we apply pre processing techinques to increase the productivity of the mdoel and reduce noise.[7] Sharpening Sharpening is a preprocessing technique used to enhance edges and fine details in an image by amplifying high-frequency components. The sharpening process can be math- ematically represented as: g(x, y) =f(x, y) +k\u00b7gmask(x, y) (3.5) where: \u2022f(x, y)is the original image . \u2022g(x, y)is the sharpened image . \u2022gmask(x, y)is the mask , obtained by subtracting a blurred version of the image from its original version. Department of CSE, IIITDM Kancheepuram, May 2025 14 CHAPTER 3. WORK DONE CS21B2021 \u2022kis aweight factor that controls the degree of sharpness. Mask Computation The sharpening mask is computed using a weighted median filter. One common filter used for this purpose is the Laplacian filter , which enhances edges. The corresponding kernel is: \uf8ee \uf8ef\uf8ef\uf8ef\uf8f00\u22121 0 \u22121 5 \u22121 0\u22121 0\uf8f9 \uf8fa\uf8fa\uf8fa\uf8fb Working Mechanism 1. Apply the weighted filter to detect edges. 2. Subtract a blurred version of the image from the original to create the sharpening mask. 3. Add the sharpening mask to the original image, scaled by a factor k. Contrast Limited Adaptive Histogram Equalization (CLAHE) Contrast Limited Adaptive Histogram Equalization (CLAHE) is an image preprocess- ing technique that enhances contrast adaptively while preventing noise amplification. Working Mechanism 1.Divide the Image : The image is split into small regions (tiles). 2.Equalize Histogram Locally : Each region undergoes histogram equalization in- dependently. 3.Clip Histogram : To prevent noise over-amplification, a contrast limit is applied to the histogram. 4.Interpolate : The processed regions are blended smoothly to avoid artificial bound- aries. Department of CSE, IIITDM Kancheepuram, May 2025 15 CHAPTER 3. WORK DONE CS21B2021 Mathematical Representation For a given pixel intensity p, the new intensity p\u2032is computed as: p\u2032=p\u2212pmin pmax\u2212pmin\u00d7255 (3.6) where: \u2022pminandpmaxare the minimum and maximum pixel values in the local histogram. Following muzzle detection with YOLOv7, we developed a recognition system to identify individual cattle using unique pattern features. 3.3.2 Feature Extraction Techniques For Muzzle recognition Facnet with Triplet Loss Initial attempts with Face net with triplet loss [7] proved ineffective due to the imbal- ance of the data set.FaceNet with triplet loss failed because the triplets in the dataset were unbalanced and poorly chosen. The model needs clear and well-structured an- chor, positive, and negative examples to learn meaningful differences. If the dataset has inconsistent images or badly matched triplets, the model gets confused and cannot learn properly. As a result, it struggles to create good features and performs poorly. \u2022Dataset: 268 individual cattle (4,449 training + 494 validation images) \u2022Challenge: Triplet loss requires balanced positive/negative pairs, which our dataset lacked SIFT as Feature Extractor We have also use SIFT as Feature Extractor[8] for its robustness,but SIFT (Scale- Invariant Feature Transform) does not work well when images are blurry or low-quality because it looks for sharp details like edges, corners, and patterns to find important points. If the muzzle image is not clear \u2014 for example, if it is blurry, dark, or low- resolution \u2014 these details become hard to see or even disappear. Without clear details, Department of CSE, IIITDM Kancheepuram, May 2025 16 CHAPTER 3. WORK DONE CS21B2021 SIFT cannot find enough good points to compare or match between images. This makes it difficult to use SIFT for tasks like recognizing or matching muzzles when the photos are not sharp and well-defined. As we are taking out muzzle image out from the cattle using YOLO , the cropped out image is not very clear so that SIFT cannot be able to derive the feature properly. Figure 3.7: Muzzle image of same Cattle Figure 3.8: Matches After applying SIFT ResNet50 model as a feature extractor Our solution employed a modified ResNet50 model as a feature extractor. \u2022Architecture: Adapted ResNet50 (loaded from FEAT_WEIGHTS ) \u2022Output: 2048-dimensional normalized muzzle embeddings \u2022Training: \u2013Input: 224\u00d7224 RGB muzzle crops (from YOLOv7 detection) \u2013Augmentation: Random flips, rotations, and normalization (mean/std = [0.5, 0.5, 0.5]) Department of CSE, IIITDM Kancheepuram, May 2025 17 CHAPTER 3. WORK DONE CS21B2021 \u2013Loss: Contrastive loss based on cosine similarity \u2022Database: Embeddings stored in FAISS vector database ( cattle_embs.pkl ) for efficient similarity search The collected dataset was preprocessed by: \u2022 Annotating muzzle regions for detection training \u2022 Standardizing all extracted muzzle images to a uniform dimension \u2022 Normalizing pixel values to the [0,1] range \u2022 Applying contrast enhancement to improve feature visibility \u2022 Splitting the dataset into training (1,200 images), validation (250 images), and test sets (150 images) 3.4 Recognition Framework Development 3.4.1 ResNet50 - Deep Residual Network with Skip Connections ResNet50 is a deep convolutional neural network (CNN) that is part of the ResNet (Residual Network) family. It addresses the vanishing gradient problem in deep net- works using skip connections (residual connections) . Key Features \u2022Skip Connections : Allow gradients to bypass multiple layers, preventing infor- mation loss. \u2022Bottleneck Blocks : Uses three-layer residual blocks (1x1, 3x3, and 1x1 convo- lutions) to improve efficiency. \u202250 Layers Deep : Suitable for large-scale image classification tasks. Advantages \u2022 Handles very deep architectures efficiently. \u2022 Reduces training difficulty by enabling better gradient flow. \u2022 Achieves state-of-the-art performance in image recognition. Department of CSE, IIITDM Kancheepuram, May 2025 18 CHAPTER 3. WORK DONE CS21B2021 Figure 3.9: ResNet50 Architecture with Residual Connections 3.5 Feature Extraction and Database Integration 3.5.1 ResNet50 Adaptation for Muzzle Recognition We implemented a customized ResNet50 backbone",
      "filename": "cs21b2021_final_report.pdf"
    },
    {
      "doc_id": "9d57ba83-f481-4da1-b910-122d8684ae6c",
      "chunk_idx": 7,
      "text": "was preprocessed by: \u2022 Annotating muzzle regions for detection training \u2022 Standardizing all extracted muzzle images to a uniform dimension \u2022 Normalizing pixel values to the [0,1] range \u2022 Applying contrast enhancement to improve feature visibility \u2022 Splitting the dataset into training (1,200 images), validation (250 images), and test sets (150 images) 3.4 Recognition Framework Development 3.4.1 ResNet50 - Deep Residual Network with Skip Connections ResNet50 is a deep convolutional neural network (CNN) that is part of the ResNet (Residual Network) family. It addresses the vanishing gradient problem in deep net- works using skip connections (residual connections) . Key Features \u2022Skip Connections : Allow gradients to bypass multiple layers, preventing infor- mation loss. \u2022Bottleneck Blocks : Uses three-layer residual blocks (1x1, 3x3, and 1x1 convo- lutions) to improve efficiency. \u202250 Layers Deep : Suitable for large-scale image classification tasks. Advantages \u2022 Handles very deep architectures efficiently. \u2022 Reduces training difficulty by enabling better gradient flow. \u2022 Achieves state-of-the-art performance in image recognition. Department of CSE, IIITDM Kancheepuram, May 2025 18 CHAPTER 3. WORK DONE CS21B2021 Figure 3.9: ResNet50 Architecture with Residual Connections 3.5 Feature Extraction and Database Integration 3.5.1 ResNet50 Adaptation for Muzzle Recognition We implemented a customized ResNet50 backbone (loaded from FEAT_WEIGHTS ) with the final classification layer removed to extract robust muzzle features. This adap- tation produces 2048-dimensional normalized embeddings optimized for cosine simi- larity comparison. Key Adjustments for Imbalanced Data \u2022Dataset Challenges: \u2013268 distinct cattle with imbalanced distribution (4,449 training + 494 vali- dation images) \u2013Some cattle had only 1-2 images, making triplet loss impractical \u2022Solution: \u2013Replaced triplet loss with cosine similarity-based contrastive loss \u2013Input: 224\u00d7224 RGB muzzle crops (from YOLOv7 detection) \u2013Augmentation: Random flips, rotations, and normalization (mean/std = [0.5, 0.5, 0.5]) 3.5.2 FAISS Database Integration \u2022Embedding Storage: \u2013Computed embeddings stored in FAISS vector database ( cattle_embs.pkl ) \u2013Enables efficient cosine similarity queries for real-time identification \u2013Returns top-1 match for each query \u2022Dynamic Updates: Department of CSE, IIITDM Kancheepuram, May 2025 19 CHAPTER 3. WORK DONE CS21B2021 \u2013New cattle added via /add endpoint \u2013Automatically updates FAISS database with new embeddings and metadata 3.6 Cattle Enrollment System Our system provides two seamless methods for registering new cattle: via direct API calls or through the mobile application interface. API Enrollment Process The/add endpoint handles new cattle registration through a streamlined workflow: \u2022Image Processing: \u2013Accepts muzzle photo uploads via mobile app or direct API calls \u2013Performs automatic muzzle detection using YOLOv7 \u2013Validates image quality before further processing \u2022Feature Extraction: \u2013Processes validated muzzle crops through ResNet50 \u2013Generates and normalizes 2048D feature embeddings \u2013Stores embeddings in cattle_embs.pkl FAISS database \u2022Metadata Management: \u2013Maintains comprehensive records in cattle_meta.json \u2013Tracks cattle ID, image paths, and timestamps \u2013Ensures full auditability of all registrations Mobile Application Enrollment The Flutter mobile app provides a user-friendly interface for cattle registration: \u2022User Interface Features: \u2013Automatic ID generation via /next-id endpoint \u2013Batch image upload from gallery or direct camera capture \u2013Real-time YOLOv7 validation (rejects poor-quality images) \u2013Progress tracking for multiple cattle registration \u2022Backend Integration: Department of CSE, IIITDM Kancheepuram, May 2025 20 CHAPTER 3. WORK DONE CS21B2021 \u2013Seamless communication with /add endpoint \u2013Clear status messages (success/failure notifications) \u2013Automatic retry mechanism for failed uploads \u2022Offline Capabilities: \u2013Local storage of pending registrations \u2013Automatic synchronization when connectivity resumes \u2013Conflict resolution for concurrent edits The enrollment system maintains data integrity through: \u2022 SHA-256 checksums for all uploaded images \u2022 Automatic duplicate detection \u2022 Role-based access control for registrations \u2022 Comprehensive audit logging 3.7 Chatbot Integration for Veterinary Support To enhance system utility, we integrated an LLM-driven chatbot [9] for disease diagno- sis and treatment recommendations: 3.7.1 Data Sources \u2022PDFs: \"Cattle Diseases: A Farmer\u2019s Guide\" (manually curated) \u2022JSON: 200+ structured disease profiles (symptoms, prevention, treatment) 3.7.2 Implementation Details \u2022Vector Database: \u2013FAISS embeddings generated using HuggingFace\u2019s all-MiniLM-L6-v2 model \u2022Query Handling: \u2013Natural language processing via LangChain \u2013Returns context-sensitive responses from knowledge base \u2022API Endpoint: \u2013/chat accepts natural language queries (e.g., \"My cow has swollen eyes\u2014possible causes?\") Department of CSE, IIITDM Kancheepuram, May 2025 21 CHAPTER 3. WORK DONE CS21B2021 Figure 3.10: Cattle registration interface showing ID generation and image upload func- tionality Department of CSE, IIITDM Kancheepuram, May 2025 22 CHAPTER 3. WORK DONE CS21B2021 Figure 3.11: Chatbot interface for veterinary advice in the mobile application Department of CSE, IIITDM Kancheepuram, May 2025 23 CHAPTER 3. WORK DONE CS21B2021 3.7.3 Mobile Application Implementation The system was deployed as a Flutter-based mobile app with camera integration and offline capabilities: \u2022Camera Integration: \u2013Users capture or upload photos for muzzle detection \u2013/identify endpoint returns cattle ID and similarity score \u2022Chatbot Access: \u2013Farmer queries via text input field \u2013Responses displayed in chat UI (Figure 4.5) \u2022Offline Mode: \u2013Local caching for areas with limited connectivity 3.8 Key Innovations \u2022YOLOv7-Based Detection: Custom-trained for real-world variability (distance, color, occlusion) \u2022ResNet50 Feature Extraction: Optimized pipeline for imbalanced datasets \u2022Modular Mobile Design: \u2013Flutter frontend with real-time camera detection \u2013Offline functionality for resource-limited environments \u2022Veterinary Chatbot: LLM-powered diagnostic assistance and treatment guid- ance Department of CSE, IIITDM Kancheepuram, May 2025 24 CHAPTER 3. WORK DONE CS21B2021 Figure 3.12: Mobile application interface showing the cattle identification feature Department of CSE, IIITDM Kancheepuram, May 2025 25 CHAPTER 4 CURRENT RESULTS 4.1 YOLO Training Metrics Object detection models like YOLO are evaluated using key metrics such as Precision, Recall, and F1-Score.[11] 4.1.1 Precision, Recall, and F1-Score Precision ( P) measures the accuracy of detected objects: P=TP TP+FP Figure 4.1: P-curve Recall ( R) indicates how many actual objects were detected: R=TP TP+FN CHAPTER 4. CURRENT RESULTS CS21B2021 Figure 4.2: R-curve The F1-Score provides a balance between Precision and Recall: F1 = 2 \u00d7P\u00d7R P+R Figure 4.3: F1score-curve 4.1.2 Training Metrics Graphs These curves help analyze model performance at different confidence thresholds, al- lowing fine-tuning for optimal detection results. Department of CSE, IIITDM Kancheepuram, May 2025 27 CHAPTER 4. CURRENT RESULTS CS21B2021 Figure 4.4: Training Metrics Graphs 4.2 ResNet50 Recognition Performance 4.2.1 Feature Extraction and Database Integration Following muzzle detection using YOLOv7, our modified ResNet50 backbone (loaded fromFEAT_WEIGHTS ) generates 2048-dimensional normalized embeddings from muz- zle crops. These embeddings are stored",
      "filename": "cs21b2021_final_report.pdf"
    },
    {
      "doc_id": "9d57ba83-f481-4da1-b910-122d8684ae6c",
      "chunk_idx": 8,
      "text": "camera detection \u2013Offline functionality for resource-limited environments \u2022Veterinary Chatbot: LLM-powered diagnostic assistance and treatment guid- ance Department of CSE, IIITDM Kancheepuram, May 2025 24 CHAPTER 3. WORK DONE CS21B2021 Figure 3.12: Mobile application interface showing the cattle identification feature Department of CSE, IIITDM Kancheepuram, May 2025 25 CHAPTER 4 CURRENT RESULTS 4.1 YOLO Training Metrics Object detection models like YOLO are evaluated using key metrics such as Precision, Recall, and F1-Score.[11] 4.1.1 Precision, Recall, and F1-Score Precision ( P) measures the accuracy of detected objects: P=TP TP+FP Figure 4.1: P-curve Recall ( R) indicates how many actual objects were detected: R=TP TP+FN CHAPTER 4. CURRENT RESULTS CS21B2021 Figure 4.2: R-curve The F1-Score provides a balance between Precision and Recall: F1 = 2 \u00d7P\u00d7R P+R Figure 4.3: F1score-curve 4.1.2 Training Metrics Graphs These curves help analyze model performance at different confidence thresholds, al- lowing fine-tuning for optimal detection results. Department of CSE, IIITDM Kancheepuram, May 2025 27 CHAPTER 4. CURRENT RESULTS CS21B2021 Figure 4.4: Training Metrics Graphs 4.2 ResNet50 Recognition Performance 4.2.1 Feature Extraction and Database Integration Following muzzle detection using YOLOv7, our modified ResNet50 backbone (loaded fromFEAT_WEIGHTS ) generates 2048-dimensional normalized embeddings from muz- zle crops. These embeddings are stored in a FAISS vector database ( cattle_embs.pkl ) for efficient cosine similarity searches. Implementation Details \u2022Dataset: 268 unique cattle with 4,449 training and 494 validation images \u2022Embedding Storage: FAISS enables real-time identification (top-1 match per query) \u2022Dynamic Updates: New cattle registered via /add endpoint, updating both em- beddings and metadata Testing Methodology \u2022Similar Muzzle Colors: \u2013Test case: Black vs. pink muzzles with similar patterns \u2013Similarity threshold: 0.85 \u2013Result: >95% differentiation accuracy \u2022Varying Conditions: \u2013Test case: Lighting, angles, and temporal variations \u2013Result: Consistent matches with similarity scores >0.97 Department of CSE, IIITDM Kancheepuram, May 2025 28 CHAPTER 4. CURRENT RESULTS CS21B2021 Table 4.1: ResNet50 Performance Metrics Metric Value Accuracy 94.7% F1 Score 0.935 Inference Time (ms) 38 Model Size (MB) 98 FAISS Search Time (ms) 12 4.3 Chatbot Integration and Mobile App Interface 4.3.1 LLM-Powered Veterinary Chatbot Our chatbot [9] provides disease diagnosis and treatment recommendations: \u2022Data Sources: \u2013PDF: \"Cattle Diseases: A Farmer\u2019s Guide\" (manually curated) \u2013JSON: 200+ structured disease profiles \u2022Implementation: \u2013FAISS embeddings using all-MiniLM-L6-v2 \u2013LangChain for contextual query processing \u2022Example Interaction: \u2013Input: \"My cow has swollen eyes and decreased appetite\" \u2013Output: \"Possible causes: BRD or Pink Eye. Recommend isolation and veterinary consultation.\" 4.3.2 Flutter-Based Mobile Application The system is deployed as a cross-platform Flutter app with: \u2022Camera Integration: \u2013Real-time muzzle detection via camera \u2013/identify endpoint returns cattle ID and confidence score \u2022Chatbot Features: \u2013Natural language input for health queries \u2013Response display in conversational UI (Fig. 4.5) \u2022Offline Capabilities: \u2013Local caching for limited-connectivity environments Department of CSE, IIITDM Kancheepuram, May 2025 29 CHAPTER 4. CURRENT RESULTS CS21B2021 Figure 4.5: Chatbot interface for veterinary advice in the mobile application Department of CSE, IIITDM Kancheepuram, May 2025 30 CHAPTER 4. CURRENT RESULTS CS21B2021 Figure 4.6: Mobile application interface showing the cattle identification feature Department of CSE, IIITDM Kancheepuram, May 2025 31 CHAPTER 4. CURRENT RESULTS CS21B2021 4.4 Integrated System Development 4.4.1 Two-Stage Pipeline Architecture Our modular pipeline consists of: \u2022Stage 1: YOLOv7 muzzle detection \u2022Stage 2: ResNet50 feature extraction and FAISS matching Key advantages: \u2022 Computational efficiency through ROI-focused processing \u2022 Modular design for future extensions (e.g., disease detection) 4.4.2 Evaluation Metrics Comprehensive testing yielded: \u2022Detection Performance: \u2013Precision: 94.8% \u2013Recall: 92.3% \u2013mAP@0.5: 93.6% \u2013Inference time: 45ms \u2022Recognition Metrics: \u2013Accuracy: 94.7% \u2013False Positive Rate: 2.3% \u2013False Negative Rate: 1.9% \u2013Optimal similarity threshold: 0.85 4.5 Current Implementation Status \u2022 YOLOv7 model trained on 1,600 annotated muzzle images \u2022 ResNet50+FAISS pipeline achieving 94.7% identification accuracy \u2022 Dynamic database updates via /add endpoint \u2022 Groq-powered chatbot for veterinary guidance \u2022 Functional Flutter app with camera and offline capabilities \u2022 Future work: Disease detection and vaccination tracking modules Department of CSE, IIITDM Kancheepuram, May 2025 32 CHAPTER 5 OUR COLLABORATIVE CONTRIBUTIONS This project was developed jointly by our team (Sai Dheeraj - CS21B2021 and Non- iesh Reddy - CS21B2032). This chapter highlights our shared efforts and individual strengths in creating this comprehensive system. 5.1 Initial Research and Planning In the foundational phase, we combined our skills to establish the project direction: \u2022Our Joint Efforts: \u2013Researched computer vision approaches for cattle biometrics \u2013Consulted with Dr. Rahul Raman to refine our approach \u2013Established requirements for real-world farm deployment \u2022Individual Strengths: \u2013Sai focused on architectural design and technical specifications \u2013Noniesh specialized in data collection and preprocessing Together, we created a robust project plan with modular components for future ex- pansion. 5.2 Building the Detection System We worked closely to develop the YOLOv7 detection framework: \u2022Our Collaborative Process: \u2013Jointly trained and evaluated multiple model variants \u2013Developed comprehensive testing protocols \u2013Optimized performance for farm conditions \u2022Complementary Roles: CHAPTER 5. OUR COLLABORATIVE CONTRIBUTIONS CS21B2021 \u2013Sai led model architecture and hyperparameter tuning \u2013Noniesh drove performance analysis and validation Our teamwork resulted in a 94.8% precise detection system capable of handling diverse real-world scenarios. 5.3 Developing the Recognition Pipeline We combined our expertise to create the recognition system: \u2022Our Shared Work: \u2013Designed the end-to-end recognition workflow \u2013Implemented the FAISS database integration \u2013Developed the dynamic update functionality \u2022Specialized Contributions: \u2013Sai architected the ResNet50 modification \u2013Noniesh focused on testing and edge cases Our solution achieved 94.7% accuracy through this balanced collaboration. 5.4 Integrating the Complete System We worked side-by-side to combine all components: \u2022Our Joint Implementation: \u2013Designed the Flutter app interface together \u2013Developed the chatbot integration jointly \u2013Created seamless pipeline connections \u2022Parallel Development: \u2013Noniesh built the veterinary knowledge base \u2013Sai implemented the camera and offline features Our integrated system reflects the strength of our partnership. Department of CSE, IIITDM Kancheepuram, May 2025 34 CHAPTER 5. OUR COLLABORATIVE CONTRIBUTIONS CS21B2021 5.5 Documentation and Future Vision We collaborated on all aspects of project completion: \u2022Shared Documentation: \u2013Co-created all technical documentation \u2013Jointly prepared presentation materials \u2013Developed the demonstration video together \u2022Our Future Plans: \u2013Expanding disease detection capabilities \u2013Enhancing the veterinary knowledge base \u2013Improving mobile app functionality Every aspect of this project represents our shared commitment and complementary skills. Department of",
      "filename": "cs21b2021_final_report.pdf"
    },
    {
      "doc_id": "9d57ba83-f481-4da1-b910-122d8684ae6c",
      "chunk_idx": 9,
      "text": "performance analysis and validation Our teamwork resulted in a 94.8% precise detection system capable of handling diverse real-world scenarios. 5.3 Developing the Recognition Pipeline We combined our expertise to create the recognition system: \u2022Our Shared Work: \u2013Designed the end-to-end recognition workflow \u2013Implemented the FAISS database integration \u2013Developed the dynamic update functionality \u2022Specialized Contributions: \u2013Sai architected the ResNet50 modification \u2013Noniesh focused on testing and edge cases Our solution achieved 94.7% accuracy through this balanced collaboration. 5.4 Integrating the Complete System We worked side-by-side to combine all components: \u2022Our Joint Implementation: \u2013Designed the Flutter app interface together \u2013Developed the chatbot integration jointly \u2013Created seamless pipeline connections \u2022Parallel Development: \u2013Noniesh built the veterinary knowledge base \u2013Sai implemented the camera and offline features Our integrated system reflects the strength of our partnership. Department of CSE, IIITDM Kancheepuram, May 2025 34 CHAPTER 5. OUR COLLABORATIVE CONTRIBUTIONS CS21B2021 5.5 Documentation and Future Vision We collaborated on all aspects of project completion: \u2022Shared Documentation: \u2013Co-created all technical documentation \u2013Jointly prepared presentation materials \u2013Developed the demonstration video together \u2022Our Future Plans: \u2013Expanding disease detection capabilities \u2013Enhancing the veterinary knowledge base \u2013Improving mobile app functionality Every aspect of this project represents our shared commitment and complementary skills. Department of CSE, IIITDM Kancheepuram, May 2025 35 CHAPTER 6 FUTURE SCOPE 6.1 Introduction Building on our current success in cattle identification and health monitoring, we outline an ambitious yet practical roadmap for system enhancement. Our future development focuses on five key areas: \u2022 Lightweight image enhancement for low-quality inputs \u2022 Edge-optimized models for real-time performance \u2022 Integrated disease detection capabilities \u2022 Advanced AI veterinary assistant features \u2022 Robust offline functionality for remote operations 6.2 Lightweight Image Enhancement To address challenges with blurry or poorly illuminated muzzle crops: \u2022CLAHE + Sharpening Pipeline: \u2013Enhance contrast and edges without SRGAN-like artifacts \u2013Optimized for edge devices (Raspberry Pi compatible) \u2022Domain-Specific Super-Resolution: \u2013Train lightweight ESRGAN exclusively on muzzle images \u2013Preserve crucial biometric patterns during enhancement CHAPTER 6. FUTURE SCOPE CS21B2021 6.3 Edge-Optimized YOLOv7 Deployment For real-time farm applications: \u2022Model Optimization: \u2013Quantize to ONNX/TensorRT (NVIDIA Jetson) and TFLite (Android) \u2013Implement pruning and distillation techniques \u2022Hardware Integration: \u2013Raspberry Pi/Jetson Nano deployment \u2013Autonomous monitoring with camera modules 6.4 Integrated Disease Detection Expanding our health monitoring capabilities: \u2022Computer Vision Module: \u2013Transfer learning with ResNet50/EfficientNet \u2013Attention mechanisms for lesion detection \u2022System Integration: \u2013Disease embeddings in FAISS database \u2013Real-time health alerts via mobile app 6.5 Mobile Application Enhancements Improving farmer accessibility: \u2022Offline-First Architecture: \u2013Local caching of cattle IDs and health records \u2013Synchronization when connectivity available \u2022Health Management Tools: \u2013Vaccination and treatment reminders \u2013Interactive herd health dashboard Department of CSE, IIITDM Kancheepuram, May 2025 37 CHAPTER 6. FUTURE SCOPE CS21B2021 6.6 AI Veterinary Assistant Advancing our chatbot capabilities: \u2022Retrieval-Augmented Generation (RAG): \u2013Enhanced Groq LLM (llama3-8b) integration \u2013Context-aware responses from FAISS-embedded knowledge \u2022Multi-Modal Support: \u2013Combined text + image queries \u2013Local language interfaces (Hindi, Spanish) 6.7 Technical Refinements Based on current implementation insights: \u2022 Maintained cosine similarity approach for imbalanced datasets \u2022 Adopted CLAHE over SRGAN for artifact-free enhancement \u2022 Committed to YOLOv7 optimization for edge deployment \u2022 Extended existing /chat endpoint with RAG architecture \u2022 Leveraged current disease data (PDFs/JSONs) for seamless expansion This evolutionary roadmap ensures our system grows into a comprehensive live- stock management solution while building on existing strengths. Department of CSE, IIITDM Kancheepuram, May 2025 38 REFERENCES [1] I. S. M. R.-S. S. T. D. K. Stevan Stankovski, Gordana Ostojic, \u201cDairy cow moni- toring by rfid,\u201d Computers and Electronics in Agriculture , 2012. [2] M. Hansen and J. Smith, \u201cCattle biometrics: The role of muzzle patterns in iden- tification,\u201d Livestock Science , vol. 232, pp. 104\u2013117, 2020. [3] S. K. . S. K. Singh, \u201cAutomatic identification of cattle using muzzle point pat- tern: a hybrid feature extraction and classification paradigm,\u201d Computers and AI in Agriculture , 2016. [4] M. Rony, D. Barai, Riad, and Z. Hasan, \u201cCattle external disease classification using deep learning techniques,\u201d in 2021 12th International Conference on Com- puting Communication and Networking Technologies (ICCCNT) , 2021, pp. 1\u20137. [5] X. Wang, X. He, and Y . Li, \u201cDeep feature learning for biometric recognition in cattle identification,\u201d IEEE Transactions on Image Processing , vol. 28, pp. 4562\u2013 4575, 2019. [6] J. Redmon, S. Divvala, R. Girshick, and A. Farhadi, \u201cYou only look once: Unified, real-time object detection,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2016, pp. 779\u2013788. [7] S. K. S. K. P. S. I. R. Hasan Zohirul Islam1, , \u201cMuzzle-based cattle identification system using artificial intelligence,\u201d Computers and AI in Agriculture , 2024. [8] A. I. Awad, H. Zawbaa, H. Mahmoud, E. Rashwan, R. Fayed, and A. E. Hassanien, \u201cA robust cattle identification scheme using muzzle print images,\u201d pp. 529\u2013534, 01 2013. [9] Y . Gao, Y . Xiong, X. Gao, K. Jia, J. Pan, Y . Bi, Y . Dai, J. Sun, M. Wang, and H. Wang, \u201cRetrieval-augmented generation for large language models: A survey,\u201d 2024. [Online]. Available: https://arxiv.org/abs/2312.10997 [10] D. D. P. Mr. Rajeshwaran K, Ancy A and D. S. D, \u201cMobile app for muzzle pattern recognition for cattle identification using feature extraction,\u201d Computers and AI in Agriculture , 2023. [11] I. Goodfellow, Y . Bengio, and A. Courville, Deep Learning . MIT Press, 2016. 39 Weekly Review Report 40 Plagiarism Report Insert the 1st page of the plagiarism report (containing the similarity index). Make sure that it is duly signed by you as well as your supervisor. 41 REFERENCES CS21B2021 Department of CSE, IIITDM Kancheepuram, May 2025 42",
      "filename": "cs21b2021_final_report.pdf"
    },
    {
      "doc_id": "9d57ba83-f481-4da1-b910-122d8684ae6c",
      "chunk_idx": 10,
      "text": "Dai, J. Sun, M. Wang, and H. Wang, \u201cRetrieval-augmented generation for large language models: A survey,\u201d 2024. [Online]. Available: https://arxiv.org/abs/2312.10997 [10] D. D. P. Mr. Rajeshwaran K, Ancy A and D. S. D, \u201cMobile app for muzzle pattern recognition for cattle identification using feature extraction,\u201d Computers and AI in Agriculture , 2023. [11] I. Goodfellow, Y . Bengio, and A. Courville, Deep Learning . MIT Press, 2016. 39 Weekly Review Report 40 Plagiarism Report Insert the 1st page of the plagiarism report (containing the similarity index). Make sure that it is duly signed by you as well as your supervisor. 41 REFERENCES CS21B2021 Department of CSE, IIITDM Kancheepuram, May 2025 42",
      "filename": "cs21b2021_final_report.pdf"
    },
    {
      "doc_id": "3334178a-198f-4ff3-bb11-795ab7bae0c5",
      "chunk_idx": 11,
      "text": "Bharath vamsi \u2642phone+1-7739687965 Computer Science and Engineering /envel\u2322pebharathvamsikoneti@gmail.com /linkedinLinkedIn Profile About Me IT and Data Analytics professional combining technical expertise with strong problem-solving abilities. Proficient in systems administration, data analysis, and enterprise software implementation. Experience in Python programming, data visualization, and IT support, with a proven track record of delivering data-driven solutions. Seeking an IT role to leverage both technical and analytical skills in a dynamic enterprise environment. Education \u2022Governors State University Present Master of Science: Computer Science Chicago, IL \u2022Vellore Institute of Technology 2018-2022 Bachelor of Science: Computer Science India Experience \u2022Java Fullstack Developer OVS Technologies Inc., Chicago, IL (Remote). 2024 October- 2025 March \u2013Develop and maintain full-stack Java applications supporting enterprise systems and Improved system quality by identifying issues, developing SOPs, and enhancing application features.). \u2013Collaborate with cross-functional teams to implement efficient technical designs. Projects \u2013Early Fire Detection Using Cloud \u2217Developed a cloud-based fire detection system using Arduino and flame sensors, showcasing problem-solving skills and innovation in industrial safety. \u2217Seamlessly integrated cloud services with hardware components for real-time data analysis and alerts, optimizing system performance for timely fire hazard detection. \u2217Implemented a proactive solution to enhance workplace safety by preemptively identifying fire risks, demonstrat- ing a commitment to safeguarding personnel and assets in industrial settings. \u2013College Event Management Portal HTML, CSS, JavaScript, MySQL, PHP \u2217Developed a responsive web application to manage event registrations, schedules, and feedback. \u2217Implemented admin dashboard for event coordinators with real-time participant tracking. \u2217Ensured secure login systems and user role-based access. \u2013Employee Performance Analysis Python \u2217Designedandimplementedperformancemetricstoevaluateemployeeproductivity, efficiency, andqualityofwork. \u2217Utilized statistical analysis and data visualization techniques to identify trends and patterns in employee perfor- mance data, leading to informed decision-making on training programs and resource allocation. \u2217Spearheaded performance improvement initiatives based on data insights, resulting in a measurable increase in team efficiency and individual productivity. \u2013Accenture North America Data Analytics and Visualization Job Simulation on Forage \u2217Completed a simulation focused on advising a hypothetical social media client as a Data Analyst at Accenture \u2217Cleaned, modelled and analyzed 7 datasets to uncover insights into content trends to inform strategic decisions \u2217Prepared a PowerPoint deck and video presentation to communicate key insights for the client and internal stakeholders Technical Skills and Interests IT Support : Windows OS, Remote Support Tools, Hardware Troubleshooting Languages : Python, Java, Mysql Frameworks/Modules : NumPy,Pandas,Power Bi,Excel Networking : TCP/IP Fundamentals, Basic Network Configuration Certifications Security Analyst from NASSCOM Basic Python from HackerRank Introduction to Data Science from CISCO Accenture North America Data Analytics and Visualization Job Simulation on Forage - May 2024",
      "filename": "Bharath_resume.pdf"
    }
  ]
}